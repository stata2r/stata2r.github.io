---
title: "data.table"
authors: "Nick Huntington-Klein, Grant McDermott, and Kyle Butts"
output: html_document
---

## Introduction to data.table

The [**data.table**](https://rdatatable.gitlab.io/data.table) package centers
around **data.tables**, which are highly efficient data frames that can be
manipulated using the package's concise syntax. For example, say we have a
data.table called `dat` (you can call it whatever you want). Then we can
manipulate it by putting arguments into its square brackets, i.e. `dat[]`. The
three main components of a **data.table** operation are `i`, `j`, and `by`,
which go in the order **`dat[i, j, by]`**. Note you don't have to specify the
latter two if you're not currently using them.


- 
**`i`**, the first component, selects the rows of the data.table that you'll be working with, like how in Stata the `if` or `in` command options let you refer to certain rows.
- 
**`j`**, the second component, both selects and operates on the columns of the data.table, like how in Stata the `keep` or `drop` commands select specific columns of your data, or how `generate` or `replace` create or modify columns in your data.
- 
**`by`**, the third component, gives the variable(s) designating groups that you'll be doing your calculations within, like how in Stata you can precede a command with `bysort`.



**data.table** uses these simple components very flexibly. The upshot is that
you can perform complicated operations in a single line of concise **data.table**
code, which may have required multiple commands in other languages or libraries
to accomplish. But even if you aren't doing anything fancy, **data.table** has
you covered with a stable set of functions that can be deployed on virtually
any data wrangling task.

Like Stata, **data.table** also provides some special shortcut symbols for
common operations. For example, `_N` in Stata is equivalent to `.N` in
**data.table**, while `.(x1, x2)` is short for `list(x1, x2)`. We'll see more
examples in cheatsheat that follows. But we do want to quickly highlight one
special symbol in particular: `.SD` refers to the (S)ubset of (D)ata you're
working with. This can be used to do complex within-group calculations when you
have by specified, but more generally it's a way to perform operations on lots
of columns with one line of code. By default, `.SD` refers to all columns in the
dataset (excepting those in `by`). But you can specify the columns you want with
the `.SDcols` argument. Again, we'll see a bunch of examples below.

Finally, **data.table** is extremely fast. It has long set the standard for
in-memory data wrangling [benchmarks](https://h2oai.github.io/db-benchmark)
across a variety of libraries and languages. You will likely see an order(s) of
magnitude performance difference as you compare the code chunks below. As a
bonus for Stata users, who are used to operations changing a single dataset in
memory, many **data.table** operations can be done **in-place**. This means that
you don't have to (re)assign the result to a new **data.table**. In-place
modifications are also very efficient, since they will only affect the parts
you're actually changing, without wasting memory and time on the parts that
aren't being changed. Any time in the below cheat sheet you see a function with
the word `set` in it, or the `:=` operator, that's an in-place operation.

Before continuing, make sure that you have installed `data.table`. You only
have to do this once (or as often as you want to update the package).

```{r , eval = F}
# Install from CRAN (recommended) 
install.packages(data.table)

# Install the development version from GitHub (advanced) 
# Requires Rtools and the remotes package 
# remotes::install_github('Rdatatable/data.table')

```


Once `data.table` is installed, don't forget to load it whenever you want to
use it. Unlike Stata, you have to re-load a package every time you start a new R
session.

```{r }
# Load data.table into our current R session
library(data.table)

```


## Data I/O

Like Stata's ".dta" format, R has its own native ".rds" binary file storage type. (See also the [fst](http://www.fstpackage.org/) package.) However, we generally recommend that users avoid native—especially proprietary—data types since they hamper interoperability and reproducibility. We'll hence concentrate on common open-source file types below. We'll make an exception for .dta given our target audience, but we still recommend avoiding it if possible.


```{r read-and-write-.csv}
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')
fwrite(dat, 'flightdata.csv')

```



```{r read-and-write-.parquet, eval = F}
# These commands require the `arrow` package 
pfiles = dir(pattern = ".parquet") 
rbindlist(lapply(pfiles, arrow::read_parquet)) 
rbindlist(lapply(pfiles, arrow::read_parquet, col_select=1:10))

```



```{r read-and-write-.dta, eval = F}
# These commands require the `haven` package 
dat = haven::read_dta('filename.dta') 
setDT(dat) # Or: dat = as.data.table(dat) 
 
haven::write_dta(dat, 'filename.dta')

```


## Order


```{r sort-rows}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

setorder(dat, air_time) 
setorder(dat, air_time, dest) 
setorder(dat, -air_time)

```



```{r sort-columns}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

setcolorder(dat, c('month','day'))

```



```{r rename-columns}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# setnames(dat, old = ..., new = ...) 

setnames(dat, 'arr_delay', 'arrival_delay') 
setnames(dat, c('carrier','origin'), c('carrier_code','origin_code')) 
setnames(dat, gsub('arr_', 'arrival_', names(dat)))

```


## Subset

While it takes some doing in Stata to work with multiple data sets at once (and most people do not use Stata this way, and it doesn't work in old versions), using multiple datasets at once is standard in R, and **subsetting operations won't overwrite your original dataset**. That means you don't need to wrap everything in `preserve/restore`. However, it also means that you'll need to (re)assign your subsetted data if you want to use it again later. E.g. `dat1 = dat[origin=='LGA']`.


```{r subset-rows}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# Reminder: You'll need to (re)assign the 
# collapsed dataset if you want to use it later,
# e.g. dat1 = dat[1:200] 

dat[1:200] 
dat[day > 5 & day < 10] 
dat[between(day,5,10)] # Or: dat[day %in% 5:10] 
dat[origin=='LGA']
dat[origin %like% 'LGA'] 
dat[month %in% c(3,4,11,12)] 
dat[origin %chin% c("JFK","LGA")] # %chin% is a faster %in% for (ch)aracter strings 
dat[month!=1]

```



```{r subset-columns}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# Reminder: You'll need to (re)assign the 
# collapsed dataset if you want to use it later,
# e.g. dat1 = dat[, .(month, day, carrier)] 

dat[, .(month, day, carrier)] 
dat[, list(month, day, carrier)] # same as above 
dat[, c('month', 'day', 'carrier')] # ditto 

dat[, year:arr_delay] 
dat[, .SD, .SDcols=patterns('*_delay')] 

dat[, -c('origin', 'dest')]
dat[, c('origin', 'dest') := NULL] # same, but in-place 

# Matches the two lines on the left:
dat[, .SD, .SDcols=!is.character] 

# Matches the two lines on the left: 
dat[, .SD, .SDcols=is.integer]

```



```{r subset-rows-and-columns}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# Reminder: You'll need to (re)assign the 
# collapsed dataset if you want to use it later,
# e.g. dat1 = dat[origin=="LGA", .(month, day, carrier)] 

# Matches the two lines on the left:
dat[origin=="LGA", .(month, day, carrier)]

```



```{r drop-duplicates}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# Reminder: You'll need to (re)assign the 
# collapsed dataset if you want to use it later,
# e.g. dat1 = unique(dat) 

unique(dat) 
unique(dat, by = c('month', 'day', 'carrier'))

```



```{r drop-missing}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# Reminder: You'll need to (re)assign the 
# collapsed dataset if you want to use it later,
# e.g. dat = dat[!is.na(dest)] 

dat[!is.na(dest)]

na.omit(dat) 
na.omit(dat, cols = c('air_time', 'dest')) 
dat[!is.na(air_time) & !is.na(dest)] # Same as above

```


## Modify

In R, any missing (i.e. "NA") values will propagate during aggregating functions. If you have NA values in your real-life dataset — we don't in this example dataset — you probably want to add "na.rm=TRUE" to remove these on the fly. E.g. "mean(var1, na.rm=TRUE)" or "lapply(.SD, mean, na.rm=TRUE)".


```{r create-new-variables}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

dat[, dist_sq := distance^2] 
dat[, tot_delay := dep_delay + arr_delay] 
dat[, first_letter := substr(origin,1,1)] 
dat[, flight_path := paste(origin, dest, sep='_')] 

# Multiple variables can be created at once.
# These next few lines all do the same thing.
# Just pick your favourite. 
dat[, c('dist_sq', 'dist_cu') := .(distance^2, distance^3)] 
dat[, ':=' (dist_sq=distance^2, dist_cu=distance^3)] # "functional" equivalent 
dat[, let(dist_sq=distance^2, dist_cu=distance^3)] # dev version only

# We can also chain back-to-back dat[...][...] 
# (this holds for any data.table operation) 
dat[, dist_sq := distance^2][
    , dist_cu := distance*dist_sq]

```



**Aside:** In R, any missing (i.e. "NA") values will propagate during aggregating functions. If you have `NA` values in your real-life dataset — we don't in this example dataset — you probably want to add `na.rm=TRUE` to remove these on the fly. E.g. `mean(var1, na.rm=TRUE)` or `lapply(.SD, mean, na.rm=TRUE)`.

```{r create-new-variables-within-groups, eval = F}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

dat[, mean_dep_delay := mean(dep_delay), by=origin] 
dat[, mean_dep_delay2 := mean(dep_delay), by=.(origin, dest)] 

# Multiple grouped variables (manual demean example) 
dmcols = c('dep_delay', 'arr_delay', 'air_time') 
dat[,
    paste0(dmcols,'_dm') := lapply(.SD, \(x) x-mean(x)),  # before R 4.1 you'll need function(x) instead of the \(x) shorthand
    .SDcols = dmcols,
    by = origin] 

# Some short-cut symbols 
dat[, rows_per_carrier := .N, by = carrier] 
dat[, index_within_carrier := .I, by = carrier] 
dat[, origin_index := .GRP, by = origin]

# Refer to other rows (uses generic data set)
setorder(dat, group, time)
dat[, growth := X/shift(X, 1), by = group]
dat[, growth_since_first := X/first(X), by = group]

```



```{r work-with-dates}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# Make ourselves a date variable
dat[, date := as.IDate(paste(year, month, day, sep='-'))] 




# Pull out year (quarter, month, etc. work too)
dat[, the_year := year(date)]

# Shift forward 7 days
dat[, date := date + 7]

```



```{r modify-existing-variables}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

dat[, tot_delay := dep_delay + arr_delay] 

# Conditional modification 
dat[month==9, distance := distance + 1]
dat[1, distance := 0]

# Modify multiple variables (same function) 
cols = c('origin','dest')
dat[, (cols) := lapply(.SD, \(x) paste(x,'Airport')),  ## Note: before R 4.1 you need function(x) instead of the \(x) shorthand 
    .SDcols = cols] 

# Aside: We don't normally use a gen -> replace 
# workflow in R, the way we do in Stata. See the 
# 'Using Booleans & control-flow' section below.

```



```{r using-booleans-&-control-flow}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

dat[, long_flight := air_time>500] 

dat[, flight_length := fifelse(air_time>500, 'Long', 'Short')] 
# fifelse is like base-R ifelse, but (f)aster! 

# for nested ifelse, easier to use fcase 
dat[, flight_length2 := fcase(air_time<=120, 'Short', 
                              air_time<=500, 'Med', 
                              default = 'Long')]

```



```{r row-wise-calculations, eval = F}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# Pre-packaged row calculations: 
dat[, tot_delay := rowSums(.SD), .SDcols = patterns('*_delay')]
dat[, any_delay := fcoalesce(.SD), .SDcols = patterns('*_delay')] 

# Custom row calculations: 
dat[, new_var := mapply(custom_func, var1, var2)] 
dat[, new_var := custom_func(var1, var2), by=.I] # dev version only



```



```{r fill-in-time-series/panel-data, eval = F}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# Carry forward the last-known observation
setorder(dat, id, time)
dat[, x := nafill(x, type = 'locf'), by = id]
# Carry back the next-known observation
dat[, x := nafill(x, type = 'nocb'), by = id]

```


## Collapse

While it takes some doing in Stata to work with multiple data sets at once (and most people do not use Stata this way, and it doesn't work in old versions), using multiple datasets at once is standard in R. That means you don't need to wrap everything in `preserve/restore`. However, it also means that you'll need to (re)assign your collapsed data if you want to use it again later. E.g. `dat1 = dat[, mean(var1)]`. Also remember our earlier note about aggregating functions on columns that have missing values: Use `na.rm=TRUE` to remove these on the fly. E.g. `dat[, mean(var1, na.rm=TRUE)]`.


```{r collapse-with-no-grouping}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# Reminder: You'll need to (re)assign the 
# collapsed dataset if you want to use it later,
# e.g. dat1 = dat[, mean(dep_delay)] 

dat[, mean(dep_delay)] # Just give me the number! As a scalar. 
dat[, .(mean_ddel=mean(dep_delay))] # Give me back a data.table (note the .() here, that's what does it) 

dat[, .(mean_ddel=mean(dep_delay), mean_adel=mean(arr_delay))]
dat[, lapply(.SD, mean), .SDcols=c('arr_delay','dep_delay')] # same 
dat[, lapply(.SD, mean), .SDcols=arr_delay:dep_delay] # ditto 

dat[, lapply(.SD, mean), .SDcols=patterns('delay')] 

 # Matches the two lines on the left
dat[, lapply(.SD, mean), .SDcols=is.numeric]

```



```{r collapse-by-group}
# Reminder: You'll need to (re)assign the 
# collapsed dataset if you want to use it later,
# e.g. dat1 = dat[, mean(dep_delay), by=origin] 

dat[, .(arr_delay = mean(arr_delay)), by=carrier] 
dat[, .(mean_adel = mean(arr_delay)), by=carrier] 

dat[, .(arr_delay = mean(arr_delay)), by=.(carrier, month)] 

dat[, .(min_d = min(distance), max_d = max(distance)), by=origin] 

dat[, lapply(.SD, mean), .SDcols=patterns('_delay'), by=origin] 
dat[, lapply(.SD, mean), .SDcols=c('dep_delay','arr_delay','air_time','distance'), by=origin] 
dat[, lapply(.SD, mean), .SDcols = c(4,5,9,10), by=origin] # same as above 

# Matches the final two lines on the left: 
dat[, .(unique_dest = uniqueN(dest)), by = origin] 

# Bonus: You can also do complicated (grouped)
# aggregations as part of a dcast (i.e. reshape 
# wide) call. E.g. Get the min, mean and max
# departure and arrival delays, by origin airport.
dcast(dat, origin~., fun=list(min,mean,max),
      value.var=c('dep_delay','arr_delay'))

```



```{r count-rows}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

dat[, .N] # Or: nrow(dat) 
dat[month==10, .N] # Or: nrow(dat[month==10]
# Count rows by group:
dat[, .N, by = origin]

```



data.tables support list columns, so you can have complex objects like regression models inside a data.table. Among many other things, this means you can nest simulations inside a data.table as easily as you would perform any other (grouped) operation.

```{r grouped-calculations-and-complex-objects-inside-a-data.table}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# Example: Grouped regression 

# Let's run a separate regression of arrival delay on 
# departure delay for each month, inside our dataset 

# Just the coefficients
dat[,
    .(beta = coef(lm(arr_delay ~ dep_delay, .SD))[2]),
    by = month]

# Keep the whole model for each month
mods = dat[,
           .(mod = list(lm(arr_delay ~ dep_delay, .SD))),
           by = month] 
# Now you can do things like put all 10 models in a 
# regression table or coefficient plot 
modelsummary::msummary(mods$mod) 
modelsummary::modelplot(mods$mod, coef_omit = 'Inter')

```


## Reshape


```{r reshape-prep-(this-dataset-only)}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# We'll generate row IDs to avoid the (reshape) ambiguity 
# of repeated entries per date 
dat[, id := .I] 

```



```{r reshape-long}
ldat = melt(dat, measure=patterns('_delay'))

# Aside: you can also choose different names for your
# new reshaped columns if you'd like, e.g. 
melt(dat, measure=patterns('_delay'), variable='d_type')

```



```{r reshape-wide}
# This starts with the reshaped-long data from above
wdat = dcast(ldat, ... ~ variable)

# Aside 1: If you only want to keep the id & *_delay cols
dcast(ldat, id ~ variable)

# Aside 2: It's also possible to perform complex and 
# powerful data aggregating tasks as part of the dcast 
# (i.e. reshape wide) call.
dcast(dat, origin~., fun=list(min,mean,max),
      value.var=c('dep_delay','arr_delay'))

```


## Merge


```{r import-and-prep-secondary-dataset-on-airport-characterists}
dat2 = fread("https://vincentarelbundock.github.io/Rdatasets/csv/nycflights13/airports.csv") 
# R _doesn't_ require that merge ID variables share the 
# same name across datasets. But we'll add this anyway.
dat2[, dest := faa]

```



```{r inner-merge-(i.e.-keep-row-matches-only)}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

mdat = merge(dat, dat2, by='dest') 

```



```{r full-merge-(i.e.-keep-all-rows)}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

mdat = merge(dat, dat2, by='dest', all=TRUE)

```



```{r left-merge-(i.e.-keep-all-rows-from-"main"-dataset)}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

mdat = merge(dat, dat2, by='dest', all.x=TRUE)

```



```{r right-merge-(i.e.-keep-all-rows-from-"secondary"-dataset)}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

mdat = merge(dat, dat2, by='dest', all.y=TRUE)

```



```{r anti-merge-(i.e.-keep-non-matched-rows-only)}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

mdat = dat[!dat2, on='dest']

```



These next few examples are meant to highlight some specific data.table merge tricks. They don't really have good Stata equivalents (that we're aware of).


```{r merge-on-different-id-names}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

mdat = merge(dat, dat2, by.x='dest', by.y='faa') 

```



```{r set-keys-for-even-faster-merges-and-syntax-shortcuts}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

setkey(dat, dest); setkey(dat2, dest) 
mdat = merge(dat, dat2) ## note: don't need 'by' 

```



Non-equi joins are a bit hard to understand if you've never seen them before. But they are incredibly powerful and solve a suprisingly common problem: Merging datasets over a range (e.g. start to end dates), rather than exact matches. Simple example where we want to subset the 1st qtr flights for American Airlines and 2nd qtr flights for United Airlines:

```{r non-equi-joins}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

dat3 = data.table(carrier     = c('AA', 'UA'),
                  start_month = c(1, 4),
                  end_month   = c(3, 6)) 
dat[dat3, on = .(carrier,
                 month >= start_month,
                 month <= end_month)] 

```



Rolling joins are similar and allow you to match a set of dates forwards or backwards. For example, our `dat`  datset ends in October. Let's say we want to carry the  last known entries for American and United Airlines  forward to (random) future dates.

```{r rolling-joins}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

dat4 = data.table(carrier  = c('AA', 'UA'),
                  new_date = as.IDate(c('2014-11-01',
                                        '2014-11-15'))) 
dat[, date := as.IDate(paste(year, month, day, sep='-'))] 
dat[dat4, on = .(carrier, date=new_date), roll='nearest']

```



```{r appending-data}
#Load dat fresh so that each code chunk runs
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')

# This just appends the flights data to itself
rbindlist(list(dat, dat)) # Or rbind(dat, dat)
# The fill = TRUE option is handy if the one data set has columns the other doesn't

```

